ply
format ascii 1.0
element vertex 122709
property float x
property float y
property float z
property float red
property float green
property float blue
property float nx
property float ny
property float nz
property int label
end_header
-0.285513311624526978 -0.285513311624526978 -0.285513311624526978 0.333333343267440796 0.333333343267440796 0.333333343267440796 0.992182314395904541 0.992182314395904541 0.992182314395904541 100
-0.685262620449066162 -0.685262620449066162 -0.685262620449066162 0.32156863808631897 0.32156863808631897 0.32156863808631897 0.124719828367233276 0.124719828367233276 0.124719828367233276 100
0.0865541324019432068 0.0865541324019432068 0.0865541324019432068 0.301960796117782593 0.301960796117782593 0.301960796117782593 0.00439038965851068497 0.00439038965851068497 0.00439038965851068497 100
-0.395450800657272339 -0.395450800657272339 -0.395450800657272339 0.101960785686969757 0.101960785686969757 0.101960785686969757 0.0170046128332614899 0.0170046128332614899 0.0170046128332614899 100
-0.601520717144012451 -0.601520717144012451 -0.601520717144012451 0.0862745121121406555 0.0862745121121406555 0.0862745121121406555 -0.81804966926574707 -0.81804966926574707 -0.81804966926574707 100
0.101867020130157471 0.101867020130157471 0.101867020130157471 0.070588238537311554 0.070588238537311554 0.070588238537311554 -0.574896097183227539 -0.574896097183227539 -0.574896097183227539 100
-0.23086702823638916 -0.23086702823638916 -0.23086702823638916 0.352941185235977173 0.352941185235977173 0.352941185235977173 0.3500823974609375 0.3500823974609375 0.3500823974609375 100
-0.915210485458374023 -0.915210485458374023 -0.915210485458374023 0.380392163991928101 0.380392163991928101 0.380392163991928101 -0.89888763427734375 -0.89888763427734375 -0.89888763427734375 100
0.0785788223147392273 0.0785788223147392273 0.0785788223147392273 0.37254902720451355 0.37254902720451355 0.37254902720451355 0.263521134853363037 0.263521134853363037 0.263521134853363037 100
-0.36555856466293335 -0.36555856466293335 -0.36555856466293335 0.247058823704719543 0.247058823704719543 0.247058823704719543 0.635711312294006348 0.635711312294006348 0.635711312294006348 100
-0.915935516357421875 -0.915935516357421875 -0.915935516357421875 0.241830065846443176 0.241830065846443176 0.241830065846443176 -0.712991476058959961 -0.712991476058959961 -0.712991476058959961 100
0.0809430480003356934 0.0809430480003356934 0.0809430480003356934 0.203921571373939514 0.203921571373939514 0.203921571373939514 0.295828074216842651 0.295828074216842651 0.295828074216842651 100
-0.257887065410614014 -0.257887065410614014 -0.257887065410614014 0.0431372560560703278 0.0431372560560703278 0.0431372560560703278 0.113686293363571167 0.113686293363571167 0.113686293363571167 100
-0.65498119592666626 -0.65498119592666626 -0.65498119592666626 0.0431372560560703278 0.0431372560560703278 0.0431372560560703278 0.360390186309814453 0.360390186309814453 0.360390186309814453 100
0.101977348327636719 0.101977348327636719 0.101977348327636719 0.0450980402529239655 0.0450980402529239655 0.0450980402529239655 -0.925847887992858887 -0.925847887992858887 -0.925847887992858887 100
-0.395419269800186157 -0.395419269800186157 -0.395419269800186157 0.277124196290969849 0.277124196290969849 0.277124196290969849 0.790235757827758789 0.790235757827758789 0.790235757827758789 100
-0.601754724979400635 -0.601754724979400635 -0.601754724979400635 0.262745112180709839 0.262745112180709839 0.262745112180709839 -0.602021753787994385 -0.602021753787994385 -0.602021753787994385 100
0.0903223305940628052 0.0903223305940628052 0.0903223305940628052 0.230718955397605896 0.230718955397605896 0.230718955397605896 -0.114443123340606689 -0.114443123340606689 -0.114443123340606689 100
-0.386096358299255371 -0.386096358299255371 -0.386096358299255371 0.25294119119644165 0.25294119119644165 0.25294119119644165 -0.270448237657546997 -0.270448237657546997 -0.270448237657546997 100
-0.735077381134033203 -0.735077381134033203 -0.735077381134033203 0.238235294818878174 0.238235294818878174 0.238235294818878174 0.962349534034729004 0.962349534034729004 0.962349534034729004 100
0.0787855386734008789 0.0787855386734008789 0.0787855386734008789 0.211764708161354065 0.211764708161354065 0.211764708161354065 0.0272227134555578232 0.0272227134555578232 0.0272227134555578232 100
-0.355015009641647339 -0.355015009641647339 -0.355015009641647339 0.29233512282371521 0.29233512282371521 0.29233512282371521 0.986510097980499268 0.986510097980499268 0.986510097980499268 100
-0.684653103351593018 -0.684653103351593018 -0.684653103351593018 0.274153292179107666 0.274153292179107666 0.274153292179107666 -0.16266399621963501 -0.16266399621963501 -0.16266399621963501 100
0.0887259021401405334 0.0887259021401405334 0.0887259021401405334 0.253832429647445679 0.253832429647445679 0.253832429647445679 -0.0183910559862852097 -0.0183910559862852097 -0.0183910559862852097 100
-0.285450249910354614 -0.285450249910354614 -0.285450249910354614 0.120261438190937042 0.120261438190937042 0.120261438190937042 0.648381829261779785 0.648381829261779785 0.648381829261779785 100
-0.775096595287322998 -0.775096595287322998 -0.775096595287322998 0.117647059261798859 0.117647059261798859 0.117647059261798859 0.761315047740936279 0.761315047740936279 0.761315047740936279 100
0.0868402570486068726 0.0868402570486068726 0.0868402570486068726 0.100653596222400665 0.100653596222400665 0.100653596222400665 -0.000651292386464774609 -0.000651292386464774609 -0.000651292386464774609 100

(mink) arash@TUK-arash:~/ht/minkowski-building-segmentation$ python main.py 
/home/arash/anaconda3/envs/mink/lib/python3.8/site-packages/MinkowskiEngine/__init__.py:36: UserWarning: The environment variable `OMP_NUM_THREADS` not set. MinkowskiEngine will automatically set `OMP_NUM_THREADS=16`. If you want to set `OMP_NUM_THREADS` manually, please export it on the command line before running a python script. e.g. `export OMP_NUM_THREADS=12; python your_program.py`. It is recommended to set it below 24.
  warnings.warn(
    ____  ____  ________  __           ___    ____
   / __ \/ __ \/_  __/ / / /          /   |  /  _/
  / /_/ / /_/ / / / / / / /          / /| |  / /  
 / _, _/ ____/ / / / /_/ /          / ___ |_/ /   
/_/ |_/_/     /_/  \____/          /_/  |_/___/   
                                                  
    ______                                             __  
   / ____/________ _____ ___  ___ _      ______  _____/ /__
  / /_  / ___/ __ `/ __ `__ \/ _ \ | /| / / __ \/ ___/ //_/
 / __/ / /  / /_/ / / / / / /  __/ |/ |/ / /_/ / /  / ,<   
/_/   /_/   \__,_/_/ /_/ /_/\___/|__/|__/\____/_/  /_/|_|  
                                                           


================================
  Menu
================================
Commands:
  1. Preprocess Raw Data
  2. Train Model
  3. Test
  4. Inference
  0. Quit

Enter the command number: 2
Training Model...
INFO - 2023-04-17 17:10:49,894 - train - trying to load 1 files from train_dataset
INFO - 2023-04-17 17:10:49,894 - train - trying to load 1 files from val_dataloader
INFO - 2023-04-17 17:10:49,894 - train - trying to load 2 files from test_dataloader
INFO - 2023-04-17 17:10:49,894 - train - Preparing to train...
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
INFO - 2023-04-17 17:10:49,895 - train - Instantiating Model...
INFO - 2023-04-17 17:10:51,376 - train - training... 
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type                      | Params
----------------------------------------------------
0 | conv1 | MinkowskiConvolution      | 41.5 K
1 | bn1   | MinkowskiBatchNorm        | 64    
2 | conv2 | MinkowskiConvolution      | 67.1 M
3 | bn2   | MinkowskiBatchNorm        | 128   
4 | conv3 | MinkowskiConvolution      | 419 M 
5 | pool  | MinkowskiGlobalMaxPooling | 0     
6 | fc1   | Linear                    | 1.7 K 
7 | fc2   | Linear                    | 1.6 K 
----------------------------------------------------
486 M     Trainable params
0         Non-trainable params
486 M     Total params
1,946.337 Total estimated model params size (MB)
Validation sanity check:   0%|                              | 0/1 [00:00<?, ?it/s]Data at index 0: {'coords': array([[ 0.06993579, -0.8875114 , -0.141211  ],
       [ 0.07884964, -0.88602847, -0.14142469],
       [ 0.081388  , -0.88415694, -0.1406332 ],
       ...,
       [-0.11001813,  0.20455559,  0.07715092],
       [ 0.1696991 , -0.7833848 ,  0.06126321],
       [ 0.1398216 , -0.69006497,  0.05649293]], dtype=float32), 'features': array([[ 9.9934232e-01,  9.9934232e-01,  9.9934232e-01, -7.0566386e-02,
         9.9366534e-01,  8.7462164e-02],
       [ 9.9945182e-01,  9.9945182e-01,  9.9945182e-01, -1.3577320e-01,
         9.8568058e-01,  9.9997237e-02],
       [ 9.9958915e-01,  9.9958915e-01,  9.9958915e-01,  1.9587360e-01,
        -9.7654778e-01, -8.9375429e-02],
       ...,
       [ 9.9714798e-01,  9.9786097e-01,  9.9393940e-01,  1.6104952e-01,
        -5.3331280e-01, -8.3044595e-01],
       [ 9.9803919e-01,  9.9803919e-01,  9.9803919e-01, -5.5619329e-04,
        -2.4151134e-01,  9.7039783e-01],
       [ 6.7696702e-01,  6.8248057e-01,  5.9970367e-01, -3.1770056e-01,
         2.0898934e-01,  9.2487288e-01]], dtype=float32), 'labels': array([ 0,  0,  0, ..., 15,  1,  1])}
Coords shapes: [(31390, 3)]
Features shape: (31390, 6)
Labels shape: (31390, 25)
Input shape: torch.Size([8, 6])
Shape after conv1: torch.Size([8, 32])
Shape after conv2: torch.Size([8, 64])
Shape after conv3: torch.Size([8, 25])